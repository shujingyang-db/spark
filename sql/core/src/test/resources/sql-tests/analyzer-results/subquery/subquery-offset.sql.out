-- Automatically generated by SQLQueryTestSuite
-- !query
create table x(x1 int, x2 int)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "NOT_SUPPORTED_COMMAND_WITHOUT_HIVE_SUPPORT",
  "sqlState" : "0A000",
  "messageParameters" : {
    "cmd" : "CREATE Hive TABLE (AS SELECT)"
  }
}


-- !query
insert into x values (1, 1), (2, 2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`x`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 13,
    "stopIndex" : 13,
    "fragment" : "x"
  } ]
}


-- !query
create table y(y1 int, y2 int)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "NOT_SUPPORTED_COMMAND_WITHOUT_HIVE_SUPPORT",
  "sqlState" : "0A000",
  "messageParameters" : {
    "cmd" : "CREATE Hive TABLE (AS SELECT)"
  }
}


-- !query
insert into y values (1, 1), (1, 2), (2, 4)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`y`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 13,
    "stopIndex" : 13,
    "fragment" : "y"
  } ]
}


-- !query
select * from x where exists (select * from y where x1 = y1 limit 1 offset 2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`x`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 15,
    "fragment" : "x"
  } ]
}


-- !query
select * from x join lateral (select * from y where x1 = y1 limit 1 offset 2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`x`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 15,
    "fragment" : "x"
  } ]
}


-- !query
select * from x where x1 in (select y1 from y limit 1 offset 2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`x`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 15,
    "fragment" : "x"
  } ]
}


-- !query
select * from x where (select sum(y2) from y where x1 = y1 limit 1 offset 2) > 2
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`x`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 15,
    "fragment" : "x"
  } ]
}


-- !query
CREATE TEMPORARY VIEW EMP AS SELECT * FROM VALUES
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (200, "emp 2", date "2003-01-01", 200.00D, 10),
  (300, "emp 3", date "2002-01-01", 300.00D, 20),
  (400, "emp 4", date "2005-01-01", 400.00D, 30),
  (500, "emp 5", date "2001-01-01", 400.00D, NULL),
  (600, "emp 6 - no dept", date "2001-01-01", 400.00D, 100),
  (700, "emp 7", date "2010-01-01", 400.00D, 100),
  (800, "emp 8", date "2016-01-01", 150.00D, 70)
AS EMP(id, emp_name, hiredate, salary, dept_id)
-- !query analysis
CreateViewCommand `EMP`, SELECT * FROM VALUES
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (200, "emp 2", date "2003-01-01", 200.00D, 10),
  (300, "emp 3", date "2002-01-01", 300.00D, 20),
  (400, "emp 4", date "2005-01-01", 400.00D, 30),
  (500, "emp 5", date "2001-01-01", 400.00D, NULL),
  (600, "emp 6 - no dept", date "2001-01-01", 400.00D, 100),
  (700, "emp 7", date "2010-01-01", 400.00D, 100),
  (800, "emp 8", date "2016-01-01", 150.00D, 70)
AS EMP(id, emp_name, hiredate, salary, dept_id), false, false, LocalTempView, true
   +- Project [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
      +- SubqueryAlias EMP
         +- LocalRelation [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]


-- !query
CREATE TEMPORARY VIEW DEPT AS SELECT * FROM VALUES
  (10, "dept 1", "CA"),
  (20, "dept 2", "NY"),
  (30, "dept 3", "TX"),
  (40, "dept 4 - unassigned", "OR"),
  (50, "dept 5 - unassigned", "NJ"),
  (70, "dept 7", "FL")
AS DEPT(dept_id, dept_name, state)
-- !query analysis
CreateViewCommand `DEPT`, SELECT * FROM VALUES
  (10, "dept 1", "CA"),
  (20, "dept 2", "NY"),
  (30, "dept 3", "TX"),
  (40, "dept 4 - unassigned", "OR"),
  (50, "dept 5 - unassigned", "NJ"),
  (70, "dept 7", "FL")
AS DEPT(dept_id, dept_name, state), false, false, LocalTempView, true
   +- Project [dept_id#x, dept_name#x, state#x]
      +- SubqueryAlias DEPT
         +- LocalRelation [dept_id#x, dept_name#x, state#x]


-- !query
SELECT emp_name
FROM   emp
WHERE EXISTS (SELECT max(dept.dept_id) a
                   FROM   dept
                   WHERE  dept.dept_id = emp.dept_id
                   GROUP  BY state
                   ORDER  BY state
                   LIMIT 2
                   OFFSET 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter (dept_id#x = outer(dept_id#x))\n+- SubqueryAlias dept\n   +- View (`DEPT`, [dept_id#x,dept_name#x,state#x])\n      +- Project [cast(dept_id#x as int) AS dept_id#x, cast(dept_name#x as string) AS dept_name#x, cast(state#x as string) AS state#x]\n         +- Project [dept_id#x, dept_name#x, state#x]\n            +- SubqueryAlias DEPT\n               +- LocalRelation [dept_id#x, dept_name#x, state#x]\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 42,
    "stopIndex" : 186,
    "fragment" : "SELECT max(dept.dept_id) a\n                   FROM   dept\n                   WHERE  dept.dept_id = emp.dept_id\n                   GROUP  BY state"
  } ]
}


-- !query
SELECT emp_name
FROM   emp
JOIN LATERAL (SELECT max(dept.dept_id) a
                   FROM   dept
                   WHERE  dept.dept_id = emp.dept_id
                   GROUP  BY state
                   ORDER  BY state
                   LIMIT 2
                   OFFSET 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter (dept_id#x = outer(dept_id#x))\n+- SubqueryAlias dept\n   +- View (`DEPT`, [dept_id#x,dept_name#x,state#x])\n      +- Project [cast(dept_id#x as int) AS dept_id#x, cast(dept_name#x as string) AS dept_name#x, cast(state#x as string) AS state#x]\n         +- Project [dept_id#x, dept_name#x, state#x]\n            +- SubqueryAlias DEPT\n               +- LocalRelation [dept_id#x, dept_name#x, state#x]\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 42,
    "stopIndex" : 186,
    "fragment" : "SELECT max(dept.dept_id) a\n                   FROM   dept\n                   WHERE  dept.dept_id = emp.dept_id\n                   GROUP  BY state"
  } ]
}
